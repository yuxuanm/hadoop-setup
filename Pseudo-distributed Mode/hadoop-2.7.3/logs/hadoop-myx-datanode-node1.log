2020-12-10 00:58:32,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 00:58:32,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 00:58:32,584 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 00:58:32,742 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 00:58:32,804 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 00:58:32,804 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 00:58:32,809 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 00:58:32,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 00:58:32,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 00:58:32,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 00:58:32,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 00:58:32,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 00:58:32,902 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 00:58:32,908 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 00:58:32,911 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 00:58:32,916 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 00:58:32,917 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 00:58:32,918 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 00:58:32,918 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 00:58:32,926 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36201
2020-12-10 00:58:32,926 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 00:58:33,019 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36201
2020-12-10 00:58:33,151 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 00:58:33,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 00:58:33,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 00:58:33,225 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 00:58:33,239 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 00:58:33,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 00:58:33,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 00:58:33,276 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 00:58:33,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 00:58:33,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 00:58:33,339 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 00:58:33,340 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 00:58:33,615 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 00:58:33,618 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 1981@node1
2020-12-10 00:58:33,619 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/myx/software/hadoop/tmp/dfs/data is not formatted for namespace 1339835869. Formatting...
2020-12-10 00:58:33,619 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-9f6e8e60-3852-4044-aab6-1eba3d158b91 for directory /home/myx/software/hadoop/tmp/dfs/data
2020-12-10 00:58:33,659 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 00:58:33,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1882047690-127.0.1.1-1607561896909
2020-12-10 00:58:33,660 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909
2020-12-10 00:58:33,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909 is not formatted for BP-1882047690-127.0.1.1-1607561896909. Formatting ...
2020-12-10 00:58:33,661 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1882047690-127.0.1.1-1607561896909 directory /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909/current
2020-12-10 00:58:33,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1339835869;bpid=BP-1882047690-127.0.1.1-1607561896909;lv=-56;nsInfo=lv=-63;cid=CID-59563f72-bde7-4a5e-8cc8-f741f46d6575;nsid=1339835869;c=0;bpid=BP-1882047690-127.0.1.1-1607561896909;dnuuid=null
2020-12-10 00:58:33,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 587b818f-7b7b-4836-bfce-4173c919274a
2020-12-10 00:58:33,705 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9f6e8e60-3852-4044-aab6-1eba3d158b91
2020-12-10 00:58:33,705 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 00:58:33,709 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 00:58:33,710 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 00:58:33,710 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 00:58:33,711 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 00:58:33,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1882047690-127.0.1.1-1607561896909 on /home/myx/software/hadoop/tmp/dfs/data/current: 29ms
2020-12-10 00:58:33,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1882047690-127.0.1.1-1607561896909: 31ms
2020-12-10 00:58:33,741 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 00:58:33,741 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 00:58:33,741 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-12-10 00:58:33,744 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data
2020-12-10 00:58:33,745 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607571122745 with interval 21600000
2020-12-10 00:58:33,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 00:58:33,749 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-9f6e8e60-3852-4044-aab6-1eba3d158b91): finished scanning block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 00:58:33,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 00:58:33,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 00:58:33,812 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-9f6e8e60-3852-4044-aab6-1eba3d158b91): no suitable block pools found to scan.  Waiting 1814399931 ms.
2020-12-10 00:58:33,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=1
2020-12-10 00:58:33,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000
2020-12-10 00:58:33,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2c1a41676e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 38 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 00:58:33,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:31:37,239 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/127.0.1.1"; destination host is: "node1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 01:31:41,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:31:41,563 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 01:31:41,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:32:17,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:32:17,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:32:17,380 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 01:32:17,506 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:32:17,562 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:32:17,562 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:32:17,568 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:32:17,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:32:17,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:32:17,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:32:17,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:32:17,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:32:17,649 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:32:17,654 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:32:17,657 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:32:17,660 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:32:17,661 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:32:17,661 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:32:17,662 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:32:17,668 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43243
2020-12-10 01:32:17,668 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:32:17,743 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43243
2020-12-10 01:32:17,812 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:32:17,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:32:17,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:32:17,855 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:32:17,872 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:32:17,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:32:17,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:32:17,892 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 01:32:17,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:32:17,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:32:17,958 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:32:17,964 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:32:18,154 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 01:32:18,158 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 4338@node1
2020-12-10 01:32:18,198 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 01:32:18,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:32:18,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:32:18,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1339835869;bpid=BP-1882047690-127.0.1.1-1607561896909;lv=-56;nsInfo=lv=-63;cid=CID-59563f72-bde7-4a5e-8cc8-f741f46d6575;nsid=1339835869;c=0;bpid=BP-1882047690-127.0.1.1-1607561896909;dnuuid=587b818f-7b7b-4836-bfce-4173c919274a
2020-12-10 01:32:18,254 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9f6e8e60-3852-4044-aab6-1eba3d158b91
2020-12-10 01:32:18,254 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 01:32:18,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 01:32:18,284 WARN org.apache.hadoop.fs.FileSystem: "node1:9000" is a deprecated filesystem name. Use "hdfs://node1:9000/" instead.
2020-12-10 01:32:18,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:32:18,285 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:32:18,296 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909/current: 28672
2020-12-10 01:32:18,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1882047690-127.0.1.1-1607561896909 on /home/myx/software/hadoop/tmp/dfs/data/current: 12ms
2020-12-10 01:32:18,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1882047690-127.0.1.1-1607561896909: 14ms
2020-12-10 01:32:18,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:32:18,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 01:32:18,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-12-10 01:32:18,349 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-9f6e8e60-3852-4044-aab6-1eba3d158b91): no suitable block pools found to scan.  Waiting 1812375394 ms.
2020-12-10 01:32:18,351 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607578956351 with interval 21600000
2020-12-10 01:32:18,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 01:32:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 01:32:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 01:32:18,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=3
2020-12-10 01:32:18,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000
2020-12-10 01:32:18,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2037c8eda0c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 01:32:18,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:42:51,521 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/127.0.1.1"; destination host is: "node1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 01:42:55,121 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 01:42:55,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:43:42,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:43:42,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:43:42,989 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:43:43,045 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:43:43,045 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:43:43,050 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:43:43,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:43:43,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:43:43,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:43:43,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:43:43,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:43:43,135 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:43:43,139 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:43:43,143 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:43:43,146 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:43:43,147 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:43:43,147 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:43:43,147 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:43:43,154 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44985
2020-12-10 01:43:43,154 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:43:43,228 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44985
2020-12-10 01:43:43,291 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:43:43,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:43:43,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:43:43,332 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:43:43,341 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:43:43,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:43:43,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:43:43,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:43:43,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:43:43,419 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:43:43,423 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:43:43,621 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 01:43:43,625 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 6772@node1
2020-12-10 01:43:43,681 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:43:43,681 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:43:43,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1339835869;bpid=BP-1882047690-127.0.1.1-1607561896909;lv=-56;nsInfo=lv=-63;cid=CID-59563f72-bde7-4a5e-8cc8-f741f46d6575;nsid=1339835869;c=0;bpid=BP-1882047690-127.0.1.1-1607561896909;dnuuid=587b818f-7b7b-4836-bfce-4173c919274a
2020-12-10 01:43:43,704 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9f6e8e60-3852-4044-aab6-1eba3d158b91
2020-12-10 01:43:43,704 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 01:43:43,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 01:43:43,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:43:43,728 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:43:43,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1882047690-127.0.1.1-1607561896909/current: 32768
2020-12-10 01:43:43,738 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1882047690-127.0.1.1-1607561896909 on /home/myx/software/hadoop/tmp/dfs/data/current: 10ms
2020-12-10 01:43:43,738 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1882047690-127.0.1.1-1607561896909: 11ms
2020-12-10 01:43:43,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:43:43,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1882047690-127.0.1.1-1607561896909 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 01:43:43,739 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-12-10 01:43:43,782 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-9f6e8e60-3852-4044-aab6-1eba3d158b91): no suitable block pools found to scan.  Waiting 1811689961 ms.
2020-12-10 01:43:43,783 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607581851783 with interval 21600000
2020-12-10 01:43:43,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 01:43:43,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 01:43:43,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 01:43:43,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=4
2020-12-10 01:43:43,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1882047690-127.0.1.1-1607561896909 (Datanode Uuid 587b818f-7b7b-4836-bfce-4173c919274a) service to node1/127.0.1.1:9000
2020-12-10 01:43:43,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a312adea5b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 01:43:43,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1882047690-127.0.1.1-1607561896909
2020-12-10 01:47:10,856 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/127.0.1.1"; destination host is: "node1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 01:47:14,049 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 01:47:14,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:48:13,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:48:13,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:48:13,553 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:48:13,613 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:48:13,613 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:48:13,618 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:48:13,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:48:13,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:48:13,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:48:13,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:48:13,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:48:13,701 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:48:13,705 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:48:13,709 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:48:13,712 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:48:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:48:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:48:13,713 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:48:13,720 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38163
2020-12-10 01:48:13,720 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:48:13,790 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38163
2020-12-10 01:48:13,856 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:48:13,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:48:13,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:48:13,901 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:48:13,910 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:48:13,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:48:13,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:48:13,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:48:13,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:48:13,995 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:48:14,002 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:48:14,215 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 01:48:14,219 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 8908@node1
2020-12-10 01:48:14,220 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/myx/software/hadoop/tmp/dfs/data/
java.io.IOException: Incompatible clusterIDs in /home/myx/software/hadoop/tmp/dfs/data: namenode clusterID = CID-f2df497c-3b07-47cb-8b1e-e31e57465e40; datanode clusterID = CID-59563f72-bde7-4a5e-8cc8-f741f46d6575
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:775)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:300)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:416)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:395)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:573)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2020-12-10 01:48:14,222 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:574)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2020-12-10 01:48:14,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000
2020-12-10 01:48:14,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-12-10 01:48:16,224 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-12-10 01:48:16,227 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-12-10 01:48:16,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:49:36,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:49:36,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:49:37,062 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:49:37,115 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:49:37,115 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:49:37,121 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:49:37,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:49:37,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:49:37,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:49:37,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:49:37,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:49:37,217 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:49:37,222 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:49:37,225 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:49:37,228 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:49:37,229 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:49:37,229 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:49:37,229 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:49:37,238 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34021
2020-12-10 01:49:37,238 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:49:37,329 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34021
2020-12-10 01:49:37,448 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:49:37,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:49:37,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:49:37,503 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:49:37,514 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:49:37,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:49:37,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:49:37,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:49:37,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:49:37,621 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:49:37,623 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:49:37,858 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 01:49:37,862 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 1935@node1
2020-12-10 01:49:37,873 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/myx/software/hadoop/tmp/dfs/data/
java.io.IOException: Incompatible clusterIDs in /home/myx/software/hadoop/tmp/dfs/data: namenode clusterID = CID-f2df497c-3b07-47cb-8b1e-e31e57465e40; datanode clusterID = CID-59563f72-bde7-4a5e-8cc8-f741f46d6575
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:775)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:300)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:416)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:395)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:573)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2020-12-10 01:49:37,876 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000. Exiting. 
java.io.IOException: All specified directories are failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:574)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1362)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1327)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:223)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:802)
	at java.lang.Thread.run(Thread.java:748)
2020-12-10 01:49:37,876 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000
2020-12-10 01:49:37,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2020-12-10 01:49:39,978 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2020-12-10 01:49:39,981 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2020-12-10 01:49:39,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:57:09,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:57:09,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:57:09,796 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:57:09,852 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:57:09,852 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:57:09,855 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:57:09,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:57:09,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:57:09,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:57:09,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:57:09,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:57:09,930 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:57:09,934 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:57:09,938 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:57:09,941 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:57:09,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:57:09,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:57:09,942 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:57:09,952 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42969
2020-12-10 01:57:09,952 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:57:10,033 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42969
2020-12-10 01:57:10,093 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:57:10,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:57:10,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:57:10,151 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:57:10,161 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:57:10,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:57:10,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:57:10,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:57:10,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:57:10,237 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:57:10,238 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:57:11,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:12,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:13,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:14,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:15,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:16,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:17,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:18,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:19,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:20,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:20,300 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:57:26,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:27,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:28,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:29,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:30,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:31,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:32,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:33,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:34,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:35,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:35,313 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:57:41,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:42,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:43,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:44,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:45,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:46,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:47,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:48,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:49,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:50,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:50,331 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:57:56,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:57,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:58,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:57:59,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:00,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:01,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:02,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:03,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:04,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:05,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:05,344 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:58:11,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:12,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:13,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:14,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:15,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:16,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:17,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:18,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:19,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:20,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:20,358 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:58:26,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:27,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:28,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:29,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:30,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:31,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:32,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:33,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:34,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:35,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:35,373 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: node1/127.0.1.1:9000
2020-12-10 01:58:41,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:42,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 01:58:43,322 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 01:58:43,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 01:59:33,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 01:59:33,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 01:59:34,274 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 01:59:34,327 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 01:59:34,327 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 01:59:34,330 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 01:59:34,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 01:59:34,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 01:59:34,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 01:59:34,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 01:59:34,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 01:59:34,400 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 01:59:34,405 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 01:59:34,408 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 01:59:34,411 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 01:59:34,412 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 01:59:34,412 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 01:59:34,413 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 01:59:34,419 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42163
2020-12-10 01:59:34,419 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 01:59:34,491 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42163
2020-12-10 01:59:34,553 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 01:59:34,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 01:59:34,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 01:59:34,594 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 01:59:34,607 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 01:59:34,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 01:59:34,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 01:59:34,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 01:59:34,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 01:59:34,705 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 01:59:34,706 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 01:59:34,897 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 01:59:34,901 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 6386@node1
2020-12-10 01:59:34,902 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/myx/software/hadoop/tmp/dfs/data is not formatted for namespace 508717023. Formatting...
2020-12-10 01:59:34,903 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9 for directory /home/myx/software/hadoop/tmp/dfs/data
2020-12-10 01:59:34,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 01:59:34,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 01:59:34,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774 is not formatted for BP-1021304747-127.0.1.1-1607565561774. Formatting ...
2020-12-10 01:59:34,942 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1021304747-127.0.1.1-1607565561774 directory /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current
2020-12-10 01:59:34,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=null
2020-12-10 01:59:34,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 01:59:34,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 01:59:34,986 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 01:59:34,990 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 01:59:34,990 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 01:59:34,990 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:59:35,023 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 33ms
2020-12-10 01:59:35,024 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 34ms
2020-12-10 01:59:35,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 01:59:35,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 01:59:35,025 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-10 01:59:35,030 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data
2020-12-10 01:59:35,033 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607566703033 with interval 21600000
2020-12-10 01:59:35,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 01:59:35,036 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): finished scanning block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 01:59:35,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 01:59:35,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 01:59:35,077 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-12-10 01:59:35,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=1
2020-12-10 01:59:35,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000
2020-12-10 01:59:35,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x96b005e885,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 01:59:35,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:01:02,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "node1/127.0.1.1"; destination host is: "node1":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:520)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:01:06,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:01:07,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:01:07,515 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:01:07,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:01:40,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:01:40,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:01:40,525 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:01:40,577 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:01:40,577 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:01:40,581 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:01:40,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:01:40,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:01:40,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:01:40,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:01:40,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:01:40,655 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:01:40,659 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:01:40,663 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:01:40,666 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:01:40,667 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:01:40,667 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:01:40,667 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:01:40,674 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43717
2020-12-10 02:01:40,674 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:01:40,746 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43717
2020-12-10 02:01:40,811 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:01:40,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:01:40,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:01:40,861 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:01:40,871 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:01:40,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:01:40,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:01:40,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:01:40,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 02:01:40,960 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:01:40,961 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:01:41,172 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:01:41,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 8481@node1
2020-12-10 02:01:41,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:01:41,225 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:01:41,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:01:41,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:01:41,250 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:01:41,271 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:01:41,271 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:01:41,275 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:01:41,279 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 24576
2020-12-10 02:01:41,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 8ms
2020-12-10 02:01:41,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 12ms
2020-12-10 02:01:41,286 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:01:41,287 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:01:41,287 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2020-12-10 02:01:41,329 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1814273702 ms.
2020-12-10 02:01:41,330 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607567612330 with interval 21600000
2020-12-10 02:01:41,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 02:01:41,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 02:01:41,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:01:41,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=2
2020-12-10 02:01:41,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000
2020-12-10 02:01:41,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xb416b8768f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:01:41,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:15:56,584 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "node1/127.0.1.1"; destination host is: "node1":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:520)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:16:00,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:16:01,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:16:01,817 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:16:01,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:16:59,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:16:59,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:17:00,184 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:17:00,243 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:17:00,244 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:17:00,248 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:17:00,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:17:00,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:17:00,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:17:00,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:17:00,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:17:00,336 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:17:00,341 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:17:00,344 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:17:00,347 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:17:00,348 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:17:00,348 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:17:00,349 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:17:00,356 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42481
2020-12-10 02:17:00,356 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:17:00,426 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42481
2020-12-10 02:17:00,492 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:17:00,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:17:00,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:17:00,535 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:17:00,547 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:17:00,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:17:00,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:17:00,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:17:00,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 02:17:00,636 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:17:00,637 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:17:00,848 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:17:00,851 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 10630@node1
2020-12-10 02:17:00,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:17:00,905 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:17:00,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:17:00,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:17:00,930 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:17:00,966 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:17:00,966 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:17:00,967 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:17:00,975 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 32768
2020-12-10 02:17:00,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 9ms
2020-12-10 02:17:00,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 10ms
2020-12-10 02:17:00,977 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:17:00,977 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:17:00,977 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-10 02:17:01,035 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1813353995 ms.
2020-12-10 02:17:01,036 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607570370036 with interval 21600000
2020-12-10 02:17:01,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 02:17:01,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 02:17:01,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:17:01,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=3
2020-12-10 02:17:01,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000
2020-12-10 02:17:01,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x18a38656cb7,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:17:01,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:27:46,211 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/127.0.1.1"; destination host is: "node1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:27:49,712 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:27:49,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:28:22,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:28:22,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:28:23,069 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:28:23,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:28:23,131 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:28:23,135 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:28:23,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:28:23,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:28:23,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:28:23,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:28:23,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:28:23,219 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:28:23,223 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:28:23,226 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:28:23,229 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:28:23,231 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:28:23,231 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:28:23,231 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:28:23,237 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34081
2020-12-10 02:28:23,237 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:28:23,313 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34081
2020-12-10 02:28:23,381 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:28:23,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:28:23,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:28:23,420 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:28:23,428 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:28:23,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:28:23,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:28:23,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:28:23,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 02:28:23,530 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:28:23,531 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:28:23,730 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:28:23,734 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 13005@node1
2020-12-10 02:28:23,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:28:23,797 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:28:23,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:28:23,822 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:28:23,822 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:28:23,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:28:23,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:28:23,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:28:23,857 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 32768
2020-12-10 02:28:23,858 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 11ms
2020-12-10 02:28:23,858 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 12ms
2020-12-10 02:28:23,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:28:23,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:28:23,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-10 02:28:23,906 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1812671124 ms.
2020-12-10 02:28:23,907 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607586987907 with interval 21600000
2020-12-10 02:28:23,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 02:28:23,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 02:28:23,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:28:23,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=4
2020-12-10 02:28:23,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000
2020-12-10 02:28:24,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2293608307a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 30 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:28:24,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:33:03,196 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "node1/127.0.1.1"; destination host is: "node1":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:773)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:520)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:33:07,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:33:08,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/127.0.1.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:33:08,477 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:33:08,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:33:41,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:33:41,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:33:41,601 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:33:41,655 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:33:41,655 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:33:41,660 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:33:41,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:33:41,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:33:41,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:33:41,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:33:41,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:33:41,739 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:33:41,745 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:33:41,749 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:33:41,753 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:33:41,754 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:33:41,754 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:33:41,754 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:33:41,760 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46293
2020-12-10 02:33:41,760 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:33:41,836 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46293
2020-12-10 02:33:41,905 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:33:41,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:33:41,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:33:41,946 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:33:41,955 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:33:41,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:33:41,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:33:42,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:33:42,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9111 starting to offer service
2020-12-10 02:33:42,076 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:33:42,086 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:33:42,255 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:33:42,258 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 15236@node1
2020-12-10 02:33:42,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:33:42,301 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:33:42,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:33:42,325 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:33:42,325 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:33:42,352 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:33:42,352 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:33:42,352 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:33:42,358 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 32768
2020-12-10 02:33:42,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 7ms
2020-12-10 02:33:42,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 8ms
2020-12-10 02:33:42,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:33:42,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:33:42,360 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-12-10 02:33:42,417 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1812352613 ms.
2020-12-10 02:33:42,419 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607569767419 with interval 21600000
2020-12-10 02:33:42,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9111 beginning handshake with NN
2020-12-10 02:33:42,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9111 successfully registered with NN
2020-12-10 02:33:42,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9111 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:33:42,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9111 trying to claim ACTIVE state with txid=5
2020-12-10 02:33:42,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9111
2020-12-10 02:33:42,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2735fb46416,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 30 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:33:42,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:42:18,565 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/127.0.1.1"; destination host is: "node1":9111; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:42:21,556 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:42:21,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:43:07,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:43:07,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:43:07,860 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:43:07,913 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:43:07,913 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:43:07,917 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:43:07,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:43:07,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:43:07,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:43:07,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:43:07,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:43:07,996 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:43:08,002 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:43:08,005 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:43:08,008 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:43:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:43:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:43:08,009 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:43:08,016 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44935
2020-12-10 02:43:08,016 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:43:08,089 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44935
2020-12-10 02:43:08,162 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:43:08,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:43:08,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:43:08,236 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:43:08,245 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:43:08,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:43:08,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:43:08,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:43:08,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/127.0.1.1:9000 starting to offer service
2020-12-10 02:43:08,342 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:43:08,343 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:43:08,548 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:43:08,560 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 17649@node1
2020-12-10 02:43:08,601 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:43:08,601 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:43:08,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:43:08,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:43:08,633 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:43:08,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:43:08,676 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:43:08,677 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:43:08,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 32768
2020-12-10 02:43:08,690 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 13ms
2020-12-10 02:43:08,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 14ms
2020-12-10 02:43:08,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:43:08,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:43:08,691 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2020-12-10 02:43:08,744 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1811786286 ms.
2020-12-10 02:43:08,746 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607573739746 with interval 21600000
2020-12-10 02:43:08,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 beginning handshake with NN
2020-12-10 02:43:08,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/127.0.1.1:9000 successfully registered with NN
2020-12-10 02:43:08,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/127.0.1.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:43:08,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000 trying to claim ACTIVE state with txid=6
2020-12-10 02:43:08,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/127.0.1.1:9000
2020-12-10 02:43:08,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2f73ba0a1bb,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:43:08,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:46:17,825 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "node1/192.168.18.128"; destination host is: "node1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2020-12-10 02:46:20,822 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: node1/127.0.1.1:9000 New: node1/192.168.18.128:9000
2020-12-10 02:46:21,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: node1/192.168.18.128:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-10 02:46:22,352 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-12-10 02:46:22,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at node1/127.0.1.1
************************************************************/
2020-12-10 02:47:03,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/192.168.18.128
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 02:47:03,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 02:47:03,472 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 02:47:03,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 02:47:03,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 02:47:03,527 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 02:47:03,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 02:47:03,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 02:47:03,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 02:47:03,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 02:47:03,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 02:47:03,604 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 02:47:03,608 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 02:47:03,612 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 02:47:03,615 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 02:47:03,616 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 02:47:03,616 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 02:47:03,616 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 02:47:03,623 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41501
2020-12-10 02:47:03,623 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 02:47:03,705 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41501
2020-12-10 02:47:03,772 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 02:47:03,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 02:47:03,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 02:47:03,815 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 02:47:03,824 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 02:47:03,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 02:47:03,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 02:47:03,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 02:47:03,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.18.128:9000 starting to offer service
2020-12-10 02:47:03,913 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 02:47:03,919 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 02:47:04,106 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 02:47:04,109 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 19793@node1
2020-12-10 02:47:04,169 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:47:04,169 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:47:04,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 02:47:04,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 02:47:04,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 02:47:04,218 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 02:47:04,219 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 02:47:04,220 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:47:04,229 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current: 32768
2020-12-10 02:47:04,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 10ms
2020-12-10 02:47:04,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 11ms
2020-12-10 02:47:04,230 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 02:47:04,231 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 0ms
2020-12-10 02:47:04,231 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
2020-12-10 02:47:04,279 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1811550751 ms.
2020-12-10 02:47:04,281 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607588661281 with interval 21600000
2020-12-10 02:47:04,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 beginning handshake with NN
2020-12-10 02:47:04,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 successfully registered with NN
2020-12-10 02:47:04,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/192.168.18.128:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 02:47:04,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000 trying to claim ACTIVE state with txid=7
2020-12-10 02:47:04,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000
2020-12-10 02:47:04,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x32e11e2ce1f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 42 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 02:47:04,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 03:14:16,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741825_1001 src: /192.168.18.1:61727 dest: /192.168.18.128:50010
2020-12-10 03:14:16,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61727, dest: /192.168.18.128:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741825_1001, duration: 93352911
2020-12-10 03:14:16,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:16,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741826_1002 src: /192.168.18.1:61728 dest: /192.168.18.128:50010
2020-12-10 03:14:16,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61728, dest: /192.168.18.128:50010, bytes: 416, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741826_1002, duration: 4128659
2020-12-10 03:14:16,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:16,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741827_1003 src: /192.168.18.1:61729 dest: /192.168.18.128:50010
2020-12-10 03:14:16,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61729, dest: /192.168.18.128:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741827_1003, duration: 2020492
2020-12-10 03:14:16,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:16,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741828_1004 src: /192.168.18.1:61730 dest: /192.168.18.128:50010
2020-12-10 03:14:16,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61730, dest: /192.168.18.128:50010, bytes: 238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741828_1004, duration: 3138662
2020-12-10 03:14:16,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:16,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741829_1005 src: /192.168.18.1:61731 dest: /192.168.18.128:50010
2020-12-10 03:14:16,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61731, dest: /192.168.18.128:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741829_1005, duration: 2447495
2020-12-10 03:14:16,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:17,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741830_1006 src: /192.168.18.1:61732 dest: /192.168.18.128:50010
2020-12-10 03:14:17,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61732, dest: /192.168.18.128:50010, bytes: 189, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741830_1006, duration: 3653023
2020-12-10 03:14:17,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:28,686 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2020-12-10 03:14:28,687 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741825_1001 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741825
2020-12-10 03:14:28,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741826_1002 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-10 03:14:28,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741827_1003 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-10 03:14:28,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741828_1004 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741828
2020-12-10 03:14:28,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741829_1005 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741829
2020-12-10 03:14:28,689 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1021304747-127.0.1.1-1607565561774 blk_1073741830_1006 file /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774/current/finalized/subdir0/subdir0/blk_1073741830
2020-12-10 03:14:47,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741831_1007 src: /192.168.18.1:61760 dest: /192.168.18.128:50010
2020-12-10 03:14:47,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61760, dest: /192.168.18.128:50010, bytes: 87, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741831_1007, duration: 2672062
2020-12-10 03:14:47,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:47,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741832_1008 src: /192.168.18.1:61761 dest: /192.168.18.128:50010
2020-12-10 03:14:47,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61761, dest: /192.168.18.128:50010, bytes: 416, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741832_1008, duration: 2064737
2020-12-10 03:14:47,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:47,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741833_1009 src: /192.168.18.1:61762 dest: /192.168.18.128:50010
2020-12-10 03:14:47,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61762, dest: /192.168.18.128:50010, bytes: 78, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741833_1009, duration: 2030101
2020-12-10 03:14:47,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:47,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741834_1010 src: /192.168.18.1:61763 dest: /192.168.18.128:50010
2020-12-10 03:14:47,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61763, dest: /192.168.18.128:50010, bytes: 238, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741834_1010, duration: 6104534
2020-12-10 03:14:47,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:47,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741835_1011 src: /192.168.18.1:61764 dest: /192.168.18.128:50010
2020-12-10 03:14:47,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61764, dest: /192.168.18.128:50010, bytes: 51, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741835_1011, duration: 2885087
2020-12-10 03:14:47,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 03:14:47,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741836_1012 src: /192.168.18.1:61765 dest: /192.168.18.128:50010
2020-12-10 03:14:47,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:61765, dest: /192.168.18.128:50010, bytes: 189, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-802550431_56, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741836_1012, duration: 2261843
2020-12-10 03:14:47,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 05:41:19,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcb06a96518d,  containing 1 storage report(s), of which we sent 1. The reports had 6 total blocks and used 1 RPC(s). This took 17 msec to generate and 25 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 05:41:19,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:11:12,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/192.168.18.128
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 06:11:12,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 06:11:13,460 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 06:11:13,536 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 06:11:13,536 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 06:11:13,543 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 06:11:13,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 06:11:13,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 06:11:13,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 06:11:13,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 06:11:13,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 06:11:13,688 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 06:11:13,693 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 06:11:13,697 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 06:11:13,701 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 06:11:13,702 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 06:11:13,702 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 06:11:13,702 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 06:11:13,710 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45087
2020-12-10 06:11:13,710 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 06:11:13,798 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45087
2020-12-10 06:11:13,937 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 06:11:13,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 06:11:13,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 06:11:14,003 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 06:11:14,013 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 06:11:14,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 06:11:14,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 06:11:14,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 06:11:14,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.18.128:9000 starting to offer service
2020-12-10 06:11:14,132 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 06:11:14,133 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 06:11:14,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 06:11:14,444 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 1937@node1
2020-12-10 06:11:14,508 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:11:14,508 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:11:14,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 06:11:14,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 06:11:14,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 06:11:14,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 06:11:14,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:11:14,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 06:11:14,620 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 25ms
2020-12-10 06:11:14,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 27ms
2020-12-10 06:11:14,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 06:11:14,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 3ms
2020-12-10 06:11:14,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2020-12-10 06:11:14,699 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1799300331 ms.
2020-12-10 06:11:14,702 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607599727702 with interval 21600000
2020-12-10 06:11:14,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 beginning handshake with NN
2020-12-10 06:11:14,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 successfully registered with NN
2020-12-10 06:11:14,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/192.168.18.128:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 06:11:14,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000 trying to claim ACTIVE state with txid=88
2020-12-10 06:11:14,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000
2020-12-10 06:11:14,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9fb5a90aa,  containing 1 storage report(s), of which we sent 1. The reports had 6 total blocks and used 1 RPC(s). This took 5 msec to generate and 58 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 06:11:14,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:17:27,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = node1/192.168.18.128
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/myx/software/hadoop/etc/hadoop:/home/myx/software/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/myx/software/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/myx/software/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/myx/software/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/myx/software/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/myx/software/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.8.0_275
************************************************************/
2020-12-10 06:17:27,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-12-10 06:17:28,090 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-12-10 06:17:28,162 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-12-10 06:17:28,162 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-12-10 06:17:28,168 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-12-10 06:17:28,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is node1
2020-12-10 06:17:28,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-12-10 06:17:28,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2020-12-10 06:17:28,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2020-12-10 06:17:28,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2020-12-10 06:17:28,262 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-12-10 06:17:28,267 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-10 06:17:28,272 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-12-10 06:17:28,278 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-10 06:17:28,280 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-10 06:17:28,280 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-10 06:17:28,280 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-10 06:17:28,295 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39623
2020-12-10 06:17:28,295 INFO org.mortbay.log: jetty-6.1.26
2020-12-10 06:17:28,480 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39623
2020-12-10 06:17:28,613 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2020-12-10 06:17:28,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = myx
2020-12-10 06:17:28,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-12-10 06:17:28,673 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2020-12-10 06:17:28,685 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2020-12-10 06:17:28,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2020-12-10 06:17:28,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-12-10 06:17:28,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-12-10 06:17:28,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to node1/192.168.18.128:9000 starting to offer service
2020-12-10 06:17:28,835 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-12-10 06:17:28,836 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2020-12-10 06:17:29,008 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-10 06:17:29,014 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/myx/software/hadoop/tmp/dfs/data/in_use.lock acquired by nodename 1854@node1
2020-12-10 06:17:29,079 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:17:29,079 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/myx/software/hadoop/tmp/dfs/data/current/BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:17:29,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=508717023;bpid=BP-1021304747-127.0.1.1-1607565561774;lv=-56;nsInfo=lv=-63;cid=CID-30cc6f31-9d68-4764-a1d5-b0930dfb520e;nsid=508717023;c=0;bpid=BP-1021304747-127.0.1.1-1607565561774;dnuuid=68b24cf8-d0f9-4687-b947-04a81006b50e
2020-12-10 06:17:29,114 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9
2020-12-10 06:17:29,114 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/myx/software/hadoop/tmp/dfs/data/current, StorageType: DISK
2020-12-10 06:17:29,158 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-12-10 06:17:29,158 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:17:29,159 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 06:17:29,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1021304747-127.0.1.1-1607565561774 on /home/myx/software/hadoop/tmp/dfs/data/current: 23ms
2020-12-10 06:17:29,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1021304747-127.0.1.1-1607565561774: 24ms
2020-12-10 06:17:29,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current...
2020-12-10 06:17:29,187 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1021304747-127.0.1.1-1607565561774 on volume /home/myx/software/hadoop/tmp/dfs/data/current: 4ms
2020-12-10 06:17:29,187 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 5ms
2020-12-10 06:17:29,269 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/myx/software/hadoop/tmp/dfs/data, DS-1f9b2a54-9e32-4837-90b4-2df18da5d6c9): no suitable block pools found to scan.  Waiting 1798925761 ms.
2020-12-10 06:17:29,272 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1607590063272 with interval 21600000
2020-12-10 06:17:29,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 beginning handshake with NN
2020-12-10 06:17:29,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid null) service to node1/192.168.18.128:9000 successfully registered with NN
2020-12-10 06:17:29,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode node1/192.168.18.128:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-10 06:17:29,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000 trying to claim ACTIVE state with txid=89
2020-12-10 06:17:29,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1021304747-127.0.1.1-1607565561774 (Datanode Uuid 68b24cf8-d0f9-4687-b947-04a81006b50e) service to node1/192.168.18.128:9000
2020-12-10 06:17:29,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x90be78dae,  containing 1 storage report(s), of which we sent 1. The reports had 6 total blocks and used 1 RPC(s). This took 6 msec to generate and 59 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-10 06:17:29,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1021304747-127.0.1.1-1607565561774
2020-12-10 06:22:35,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1021304747-127.0.1.1-1607565561774:blk_1073741837_1013 src: /192.168.18.1:50668 dest: /192.168.18.128:50010
2020-12-10 06:22:35,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.18.1:50668, dest: /192.168.18.128:50010, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2065019908_1, offset: 0, srvID: 68b24cf8-d0f9-4687-b947-04a81006b50e, blockid: BP-1021304747-127.0.1.1-1607565561774:blk_1073741837_1013, duration: 28692914
2020-12-10 06:22:35,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1021304747-127.0.1.1-1607565561774:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2020-12-10 06:22:36,513 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: node1:50010:DataXceiver error processing READ_BLOCK operation  src: /192.168.18.1:50667 dst: /192.168.18.128:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readShort(DataInputStream.java:312)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:58)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:229)
	at java.lang.Thread.run(Thread.java:748)
